{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataMining\n",
    "\n",
    "**TASK** for each driver, generates the ideal standard route that the driver will have the least divergence.\n",
    "\n",
    "**Solution** DBSCAN on drivers , take the clustroid of the cluster that maximize the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print('HOME: ',HOME)\n",
    "\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "import lxml\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import HDBSCAN, DBSCAN\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "\n",
    "import umap\n",
    "\n",
    "## CONSTANTS\n",
    "STANDARD_FILE = 'standard.json'\n",
    "ACTUAL_FILE = 'actual.json'\n",
    "\n",
    "OUTPUT_FILE = 'perfectRoute.json'\n",
    "DATA_DIR = os.path.join(HOME,'data')\n",
    "\n",
    "K_SHINGLES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load standard and actual data\n",
    "with open(os.path.join('data',STANDARD_FILE)) as f:\n",
    "    standard = json.load(f)\n",
    "\n",
    "with open(os.path.join('data', ACTUAL_FILE)) as f:\n",
    "    actual = json.load(f)\n",
    "\n",
    "# load the data into a dataframe\n",
    "dfStandard = pd.DataFrame(standard)\n",
    "dfActual = pd.DataFrame(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique cities and items of the standard data\n",
    "cities = []\n",
    "items = []\n",
    "longestRoute = 0\n",
    "shortestRoute = np.inf\n",
    "maxItemQuantity = 0\n",
    "\n",
    "standardRefIds = []\n",
    "for index, s in dfStandard.iterrows():\n",
    "    #print(s)\n",
    "    idS = s['id']\n",
    "    route = s['route']\n",
    "    standardRefIds.append(int(idS[1]))\n",
    "    for trip in route:\n",
    "        cities.append(trip['from']) \n",
    "        items.extend(trip['merchandise'].keys())\n",
    "        maxItemQuantity = max(maxItemQuantity, max(trip['merchandise'].values()))\n",
    "    if len(route) > 0:\n",
    "        cities.append(route[-1]['to'])\n",
    "        \n",
    "    if len(route) > longestRoute:\n",
    "        longestRoute = len(route)\n",
    "        \n",
    "    if len(route) < shortestRoute:\n",
    "        shortestRoute = len(route)\n",
    "\n",
    "actualRefStandardIds = []\n",
    "for index, s in dfActual.iterrows():\n",
    "    #print(s)\n",
    "    idS = s['id']\n",
    "    route = s['route']\n",
    "    idStandard = s['sroute']\n",
    "    actualRefStandardIds.append(int(idStandard[1]))\n",
    "    for trip in route:\n",
    "        cities.append(trip['from'])\n",
    "        items.extend(trip['merchandise'].keys())\n",
    "        maxItemQuantity = max(maxItemQuantity, max(trip['merchandise'].values()))\n",
    "        \n",
    "    if len(route) > 0:\n",
    "        cities.append(route[-1]['to'])\n",
    "        \n",
    "    if len(route) > longestRoute:\n",
    "        longestRoute = len(route)\n",
    "    \n",
    "    if len(route) < shortestRoute:\n",
    "        shortestRoute = len(route)\n",
    "\n",
    "# find the unique cities and items\n",
    "uniqueCities = sorted(list(set(cities)))\n",
    "#uniqueCities.insert(0, 'NULL')          # add NULL city, for padding vectors with different lengths (trips in routes)\n",
    "uniqueItems = sorted(list(set(items)))\n",
    "\n",
    "if shortestRoute < 2:\n",
    "    K_SHINGLES = 2\n",
    "\n",
    "threeShingles = []\n",
    "\n",
    "for i, c1 in enumerate(uniqueCities):\n",
    "    for j, c2 in enumerate(uniqueCities):\n",
    "        if i == j:\n",
    "            continue\n",
    "        for k, c3 in enumerate(uniqueCities):\n",
    "            if j == k or i == k:\n",
    "                continue\n",
    "            threeShingles.append([c1, c2, c3])\n",
    "            \n",
    "permutations = math.perm(len(uniqueCities), K_SHINGLES)\n",
    "\n",
    "print(\"\\nUnique cities: \", uniqueCities)\n",
    "print(\"Unique items: \", uniqueItems)\n",
    "\n",
    "print(\"\\nNumber of cities: \", len(uniqueCities))\n",
    "print(\"Number of items: \", len(uniqueItems))\n",
    "\n",
    "print(\"\\nMax item quantity: \", maxItemQuantity)\n",
    "\n",
    "print(\"\\nNumber of three-shingles: \", len(threeShingles))\n",
    "\n",
    "print(f\"\\n{K_SHINGLES}-shingles: \", math.perm(len(uniqueCities), K_SHINGLES))\n",
    "print(f\"{K_SHINGLES}-shingles: \", math.comb(len(uniqueCities), K_SHINGLES))\n",
    "\n",
    "print(f\"\\n\\033[92mK-Shingles used: {K_SHINGLES} \\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Routes \n",
    "\n",
    "Using one-hot encoding of the all possible tuple of two cities (from-to) and the summed merchandise along a route weighted by the total number of merch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashShingles(shingles, n):\n",
    "    # hash shingles\n",
    "    string = \"\" \n",
    "    for shingle in shingles:\n",
    "        string += str(shingle) + \",\" # [45, 4, 8] -> \"45,4,8,\"\n",
    "    \n",
    "    return hash(string) #% n\n",
    "\n",
    "def createShingles(df, k, uniqueCities, uniqueItems, longestRoute, maxItemQuantity, permutations):\n",
    "    # create shingles for each route\n",
    "    shingles = []\n",
    "    for index, s in df.iterrows():\n",
    "        idS = s['id']\n",
    "        route = s['route']\n",
    "        shingle = [index]\n",
    "        citiesInRoute = []\n",
    "        merchandiseInRoute = np.zeros(len(uniqueItems))\n",
    "        for trip in route:\n",
    "            citiesInRoute.append(uniqueCities.index(trip['from']))\n",
    "            #merchandiseInRoute += np.array(list(trip['merchandise'].values()))\n",
    "            for item, n in trip['merchandise'].items():\n",
    "                merchandiseInRoute[uniqueItems.index(item)] += n\n",
    "        if len(route) > 0:\n",
    "            citiesInRoute.append(uniqueCities.index(route[-1]['to']))\n",
    "        if len(route) > 0:\n",
    "            merchandiseInRoute = merchandiseInRoute / (maxItemQuantity*len(route))\n",
    "        \n",
    "        hashedShingles = []\n",
    "        for i in range(len(citiesInRoute)-k+1):\n",
    "            hashedShingles.append(hashShingles(citiesInRoute[i:i+k], permutations) )\n",
    "        \n",
    "        shingle.append(np.array(hashedShingles))\n",
    "        \n",
    "        shingle.append(merchandiseInRoute) # quantity hot encoding\n",
    "        \n",
    "        shingles.append(shingle)\n",
    "        \n",
    "    return shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardSets = createShingles(dfStandard, k=K_SHINGLES, uniqueCities=uniqueCities, uniqueItems=uniqueItems, longestRoute=longestRoute, maxItemQuantity=maxItemQuantity, permutations=permutations)\n",
    "actualSets = createShingles(dfActual, k=K_SHINGLES, uniqueCities=uniqueCities, uniqueItems=uniqueItems, longestRoute=longestRoute, maxItemQuantity=maxItemQuantity, permutations=permutations)\n",
    "\n",
    "print(\"\\nstandardSets\", len(standardSets), \"shape first element\", standardSets[0][1].shape, standardSets[0])\n",
    "print(\"\\nactualSets\", len(actualSets),  \"shape first element\", standardSets[0][1].shape, actualSets[0])\n",
    "\n",
    "print(\"\\nstandardSets:\", len(standardSets))\n",
    "print(\"actualSets:\", len(actualSets))\n",
    "\n",
    "assert len(standardSets[0]) == 3, \"The length of the standard set is not equal to 3 (index, shingles, merchandise)\"\n",
    "assert len(standardSets[0][2]) == len(uniqueItems), \"The length of the merchandise vector is not equal to the number of unique items\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance and Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14, 10))\n",
    "\n",
    "for i in range(len(std_dev)):\n",
    "    coordinates = off[len(std_dev)-1-i] \n",
    "    x = [point[0] for point in coordinates]\n",
    "    y = [point[1] for point in coordinates]  \n",
    "\n",
    "    ax.scatter(x, y, s = 100,  edgecolor = \"black\", label=\"std_dev = {}\".format(std_dev[len(std_dev)-1-i]))\n",
    "    ax.scatter(0,0, s=100, color=\"black\", marker='*')\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.axhline(y=0, color='black', linestyle='--', label = \"Global minima\")\n",
    "ax.axhline(y=10, color='grey', linestyle='--')\n",
    "ax.axvline(x=0, color='black', linestyle='--')\n",
    "ax.axvline(x=10, color='grey', linestyle='--',label = \"Starting point\")\n",
    "\n",
    "ax.set_title(\"Offspring generated with different standard deviation values\", fontsize=20)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
